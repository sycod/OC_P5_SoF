{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS & env\n",
    "import yaml\n",
    "import os\n",
    "import dill as pickle\n",
    "import logging\n",
    "\n",
    "# ML\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "\n",
    "# home made functions\n",
    "from src.scrap_and_clean import preprocess_doc\n",
    "from src.models import w2v_vect_data\n",
    "from src.models import lr_predict_tags\n",
    "\n",
    "\n",
    "# logging configuration (see all outputs, even DEBUG or INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üöß foutre tout √ßa √† l'init de l'app\n",
    "# nltk downloads\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:‚öôÔ∏è Loading vectorizer...\n",
      "INFO:gensim.utils:loading Word2Vec object from models/w2v_cbow_vectorizer\n",
      "INFO:gensim.utils:loading wv recursively from models/w2v_cbow_vectorizer.wv.* with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname': 'models/w2v_cbow_vectorizer', 'datetime': '2024-06-08T00:50:19.488271', 'gensim': '4.3.2', 'python': '3.11.6 (main, Mar 19 2024, 19:27:13) [GCC 11.4.0]', 'platform': 'Linux-5.15.146.1-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "INFO:root:‚úÖ Vectorizer loaded\n",
      "INFO:root:‚öôÔ∏è Loading classifier...\n",
      "INFO:root:‚úÖ Classifier loaded\n",
      "INFO:root:‚öôÔ∏è Loading keep set...\n",
      "INFO:root:‚úÖ Keep set loaded\n",
      "INFO:root:‚öôÔ∏è Loading exclude set...\n",
      "INFO:root:‚úÖ Exclude set loaded\n"
     ]
    }
   ],
   "source": [
    "VECTORIZER_URI = \"models/w2v_cbow_vectorizer\"\n",
    "CLASSIFIER_URI = \"models/w2v_cbow_lrovr_classifier.pkl\"\n",
    "KEEP_SET_URI = \"data/keep_set.pkl\"\n",
    "EXCLUDE_SET_URI = \"data/exclude_set.pkl\"\n",
    "\n",
    "# load vectorizer\n",
    "logging.info(f\"‚öôÔ∏è Loading vectorizer...\")\n",
    "if os.path.exists(VECTORIZER_URI):\n",
    "    vectorizer = Word2Vec.load(VECTORIZER_URI)\n",
    "    logging.info(f\"‚úÖ Vectorizer loaded\")\n",
    "else:\n",
    "    logging.warning(f\"‚ö†Ô∏è No vectorizer found ‚ö†Ô∏è\")\n",
    "\n",
    "# load classifier\n",
    "logging.info(f\"‚öôÔ∏è Loading classifier...\")\n",
    "if os.path.exists(CLASSIFIER_URI):\n",
    "    with open(CLASSIFIER_URI, \"rb\") as f:\n",
    "        classifier = pickle.load(f)\n",
    "    logging.info(f\"‚úÖ Classifier loaded\")\n",
    "else:\n",
    "    logging.warning(f\"‚ö†Ô∏è No classifier found ‚ö†Ô∏è\")\n",
    "\n",
    "# load keep set (for preprocessing)\n",
    "logging.info(f\"‚öôÔ∏è Loading keep set...\")\n",
    "if os.path.exists(KEEP_SET_URI):\n",
    "    with open(KEEP_SET_URI, \"rb\") as f:\n",
    "        keep_set = pickle.load(f)\n",
    "    logging.info(f\"‚úÖ Keep set loaded\")\n",
    "else:\n",
    "    logging.warning(f\"‚ö†Ô∏è No keep set found ‚ö†Ô∏è\")\n",
    "\n",
    "# load keep set (for preprocessing)\n",
    "logging.info(f\"‚öôÔ∏è Loading exclude set...\")\n",
    "if os.path.exists(EXCLUDE_SET_URI):\n",
    "    with open(EXCLUDE_SET_URI, \"rb\") as f:\n",
    "        exclude_set = pickle.load(f)\n",
    "    logging.info(f\"‚úÖ Exclude set loaded\")\n",
    "else:\n",
    "    logging.warning(f\"‚ö†Ô∏è No exclude set found ‚ö†Ô∏è\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_input_title = \"python numpy issue: how to append arrays\"\n",
    "usr_input_body = \"\"\"\n",
    "hello everybody,\n",
    "i'm new here and i have a beginner problem, more precisely a python numpy problem:\n",
    "how can i append 2 <bold> <python> np.arrays?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jl/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user input: python numpy issue: how to append arrays \n",
      "hello everybody,\n",
      "i'm new here and i have a beginner problem, more precisely a python numpy problem:\n",
      "how can i append 2 <bold> <python> np.arrays?\n",
      "\n",
      "\n",
      "clean input: python numpy append arrays hello everybody beginner precisely python numpy append np.arrays\n"
     ]
    }
   ],
   "source": [
    "usr_input = usr_input_title + \" \" + usr_input_body\n",
    "\n",
    "# üöß MAKE FUNCTION TO CHECK INPUT FIRST (data must be at least 2 words long, not punctuation:\n",
    "# preciser \"too many frequent words\" ou \"balises HTML supprim√©es\" ou \"mod√®le entra√Æn√© sur de l'anglais\"...\n",
    "\n",
    "# def preprocess_doc(document, keep_set, exclude_set) -> str:\n",
    "#     üöß packages used -> re, nltk\n",
    "#     üöß regrouper fonctions en une seule\n",
    "#     üöß include keep_set and exclude_set in function\n",
    "#     doc_clean = clean_string(document)\n",
    "#     doc_tokens = tokenize_str(doc_clean, keep_set, exclude_set)\n",
    "#     doc_lemmed = lemmatize_tokens(doc_tokens, keep_set, exclude_set)\n",
    "#     doc_tk_clean = clean_tokens(doc_lemmed, keep_set, exclude_set)\n",
    "#     doc_preprocessed = \" \".join(doc_tk_clean)\n",
    "\n",
    "#     return doc_preprocessed\n",
    "\n",
    "input_clean = preprocess_doc(usr_input, keep_set, exclude_set)\n",
    "\n",
    "# üöß supprimer les outputs :\n",
    "# import nltk\n",
    "# nltk.download('punkt', quiet=True)\n",
    "# nltk.download('wordnet', quiet=True)\n",
    "# - faire ces downloads d√®s le lancement de l'appli (pas dans les fonctions)\n",
    "# - les supprimer des fonctions\n",
    "\n",
    "print(\"user input:\", usr_input)\n",
    "print(\"\\nclean input:\", input_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "[ 0.59756595  0.03122842 -0.38710928 -1.0459322  -1.8094747  -3.3661306\n",
      " -1.1318852   1.7912159  -2.521063   -1.5359498   1.3933053  -1.0525324\n",
      "  0.6660066   0.7565771   0.5406193   0.7922543  -0.01575549 -0.7342564\n",
      "  1.2939134   0.05723165  2.2466464   0.11878499  0.9928756  -1.2111318\n",
      "  1.11469     0.35285315  0.8928529   0.09151103 -0.41830072  1.1391151\n",
      " -1.6673391  -1.8090811  -0.5607196   0.42129993 -0.5243376  -1.0007704\n",
      " -0.58788896 -0.4786713   0.28627938 -0.7510565  -0.12019976  1.2245889\n",
      " -0.4200853   0.67028254 -1.1711799  -1.0783579   0.752281   -0.79137856\n",
      " -0.30207184  1.83658   ]\n"
     ]
    }
   ],
   "source": [
    "X_vect = w2v_vect_data(vectorizer, [input_clean.split(\" \")])\n",
    "print(X_vect.shape)\n",
    "print(X_vect[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: pandas dataframe arrays python numpy\n"
     ]
    }
   ],
   "source": [
    "predicted_probas = classifier.predict_proba(X_vect)\n",
    "lr_preds = lr_predict_tags(classifier, X_vect)\n",
    "predictions = str.join(\" \", lr_preds)\n",
    "print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
